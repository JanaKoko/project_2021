{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт нужных модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "from tqdm.auto import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужные данные\n",
    "- ``token`` — токен приложения;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '???' #Сюда вставить токен\n",
    "version = '5.92'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## База данных\n",
    "- подключение;\n",
    "- создание нужных таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('my_groups.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS posts \n",
    "(post_id text PRIMARY KEY, post_text text, post_lemmas text, smiles text, pos text,\n",
    "date text, likes int, hashtag text, domain text)\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для лемматизирования и очистки тектса\n",
    "Ещё она делает список использованных смайликов, а сами смайлики выкидывает из текста, но почему-то работает не для всех символов, нужно смотреть таблицы дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas(my_text):\n",
    "    emojis = []\n",
    "    #pos = []\n",
    "    my_pos = ''\n",
    "    tag = ''\n",
    "    if '#' in my_text:\n",
    "        new_text = my_text.split('#')[0]\n",
    "        tag = my_text.split('#')[1]\n",
    "        if '@' in tag:\n",
    "            tag = tag.split('@')[0]\n",
    "    else:\n",
    "        new_text = my_text\n",
    "    tokens = word_tokenize(new_text)\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "    stop_words = stopwords.words('russian')\n",
    "    tokens = [i for i in tokens if (i not in stop_words)]\n",
    "    two_text = ' '.join(tokens)\n",
    "    two_text = two_text.replace('.', '').replace('«', '').replace('»', '')\n",
    "    lemmas = m.lemmatize(two_text)\n",
    "    lemma_text = ''.join(lemmas[:-1])\n",
    "    for l in lemmas:\n",
    "            emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"\n",
    "            u\"\\U0001F300-\\U0001F5FF\"\n",
    "            u\"\\U0001F680-\\U0001F6FF\"\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "            u\"\\U0001F6D0-\\U0001FAD6\"\n",
    "            u\"\\U00012600-\\U000126FF\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "            emo = re.match(emoji_pattern, l)\n",
    "            if not emo == None:\n",
    "                emojis.append(emo.group())\n",
    "                lemma_text = lemma_text.replace(emo.group(), '')\n",
    "            ana = morph.parse(l)\n",
    "            pos = ana[0].tag.POS\n",
    "            if not pos == None:\n",
    "                if str(pos) == 'INFN':\n",
    "                    pos = 'VERB'\n",
    "                my_pos += str(pos) + ' '\n",
    "    new_text = re.sub(r'  +', ' ', new_text)\n",
    "    my_emojis = ''.join(emojis)\n",
    "    return new_text, lemma_text, my_emojis, my_pos, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, которая получает 2000 постов, и для каждого из них:\n",
    "- находит текст поста;\n",
    "- находит лемматизированный текст;\n",
    "- находит дату написания;\n",
    "- получает число лайков на посте;\n",
    "- записывает это всё в базу, если текст — не пустой.\n",
    "\n",
    "Возвращает текст и число записанных постов.\n",
    "\n",
    "При этом удовлетворительными признаются посты, в которых 40 или более слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_posts(my_domain, offset_list):\n",
    "    my_conn = sqlite3.connect('my_groups.db')\n",
    "    cur = my_conn.cursor()\n",
    "    one_count = 0\n",
    "    text = None\n",
    "    for o in offset_list:\n",
    "        my_data = requests.get(\n",
    "        'https://api.vk.com/method/wall.get',\n",
    "        params={\n",
    "            'domain': my_domain,\n",
    "            'access_token': token,\n",
    "            'v': version,\n",
    "            'count': 100,\n",
    "            'offset': o\n",
    "            }).json()\n",
    "        #print(my_data)\n",
    "        if 'response' in my_data.keys():\n",
    "            for i in my_data['response']['items']:\n",
    "                if len(i['text'].split(' ')) >= 40:\n",
    "                    one_count += 1\n",
    "                    text = i['text']\n",
    "                    my_new_text, lemmatized, emoj, pos, tags = lemmas(text)\n",
    "                    my_post_id = str(i['owner_id'])+'_'+str(i['id'])\n",
    "                    date = i['date']\n",
    "                    my_date = datetime.fromtimestamp(date)\n",
    "                    my_likes  = i['likes']['count']              \n",
    "                    my_conn = sqlite3.connect('my_groups.db')\n",
    "                    cur = my_conn.cursor()\n",
    "\n",
    "                    sqlite_insert_with_param = \"\"\"INSERT INTO posts\n",
    "                                      (post_id, post_text, post_lemmas, smiles, pos, date, likes, hashtag, domain)\n",
    "                                      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);\"\"\"\n",
    "\n",
    "                    data_tuple = (my_post_id, my_new_text, lemmatized, emoj, pos, my_date, my_likes, tags, my_domain)\n",
    "                    #print(data_tuple)\n",
    "                    try:\n",
    "                        cur.execute(sqlite_insert_with_param, data_tuple)\n",
    "                        my_conn.commit()\n",
    "                    except Exception:\n",
    "                        print('Это что ещё такое?')\n",
    "            if one_count >= 2000:\n",
    "                break\n",
    "        print(one_count)\n",
    "    return(text, one_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Список групп** и их короткие адреса:\n",
    "\n",
    "- **Подслушано** overhear **+**\n",
    "- **Just Story** just_str **+**\n",
    "- **My story** my_storry **+**\n",
    "\n",
    "- **Палата**:\n",
    "   - **Палата №6** pn6 **+-**\n",
    "   - **Мамдаринка** momdarinka +\n",
    "   - **Шкогвартс** shkogwarts +\n",
    "   - **Палата №666** palnom_666 +\n",
    "   - **Палата №69** palatanom69 +\n",
    "   - **Карамель** caramel6 +\n",
    "   - **Не все поймут** nevsep\n",
    "   \n",
    "- **Страшные истории** horror_tales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [] #Сюда надо добавить названия групп.\n",
    "#Я делала это не сразу, потому что иначе требовалось слишком много времени.\n",
    "for group in groups:\n",
    "    find_posts(group, [0, 100, 200, 300, 400, 500,\n",
    "                      600, 700, 800, 900, 1000,\n",
    "                      1100, 1200, 1300, 1400, 1500,\n",
    "                      1600, 1700, 1800, 1900, 2000,\n",
    "                      2100, 2200, 2300, 2400, 2500,\n",
    "                      2600, 2700, 2800, 2900, 3000,\n",
    "                      3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000,\n",
    "                      4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000,\n",
    "                      5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
